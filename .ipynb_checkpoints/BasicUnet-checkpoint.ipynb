{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "#from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "from tensorflow.keras.layers import Input, Lambda, Conv2D, Dropout, MaxPooling2D, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width_shape, height_shape = 128, 128\n",
    "batch_size = 32\n",
    "epochs = 30\n",
    "data_path_train = \"stage1_train/\"\n",
    "data_path_test = \"stage1_test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list_train = os.listdir(data_path_train)\n",
    "data_list_test = os.listdir(data_path_test)\n",
    "\n",
    "Xtrain=[] \n",
    "Ytrain=[]\n",
    "Xtest=[]\n",
    "\n",
    "for folder in tqdm(data_list_train):\n",
    "    img = imread(data_path_train +folder+ '/images/'  + folder+'.png')[:,:,:3]  \n",
    "    img = resize(img, (height_shape, width_shape),mode='constant', preserve_range=True)\n",
    "    #img = preprocess_input(img)\n",
    "    Xtrain.append(img)\n",
    "    \n",
    "    mask = np.zeros((height_shape, width_shape, 1), dtype=np.bool)\n",
    "    data_list_mask = os.listdir(data_path_train+folder+'/masks/')\n",
    "    for name_file in data_list_mask:\n",
    "        maskt = imread(data_path_train +folder+ '/masks/'  + name_file) \n",
    "        maskt = resize(maskt, (height_shape, width_shape),mode='constant', preserve_range=True)\n",
    "        maskt = np.expand_dims(maskt, axis=-1)\n",
    "        mask = np.maximum(mask, maskt) \n",
    "\n",
    "    Ytrain.append(mask)\n",
    "    \n",
    "for folder in tqdm(data_list_test):\n",
    "    img = imread(data_path_test +folder+ '/images/'  + folder+'.png')[:,:,:3]  \n",
    "    img = resize(img, (height_shape, width_shape),mode='constant', preserve_range=True)\n",
    "    #img = preprocess_input(img)\n",
    "    Xtest.append(img)\n",
    "    \n",
    "X_train = np.asarray(Xtrain,dtype=np.uint8)\n",
    "print('Xtrain:',X_train.shape)\n",
    "\n",
    "Y_train = np.asarray(Ytrain,dtype=np.bool)\n",
    "print('Ytrain:',Y_train.shape)\n",
    "\n",
    "X_test = np.asarray(Xtest,dtype=np.uint8)\n",
    "print('Xtest:',X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0])\n",
    "plt.show()\n",
    "plt.imshow(np.squeeze(Y_train[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((height_shape, width_shape, 3))\n",
    "\n",
    "#contracting path\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "maxp1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp1)\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "maxp2 = MaxPooling2D((2, 2))(conv2)\n",
    " \n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp2)\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "maxp3 = MaxPooling2D((2, 2))(conv3)\n",
    " \n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp3)\n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "maxp4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    " \n",
    "conv5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp4)\n",
    "conv5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "\n",
    "#expansive path\n",
    "up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "up6 = concatenate([up6, conv4])\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up6)\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    " \n",
    "up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "up7 = concatenate([up7, conv3])\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up7)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    " \n",
    "up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "up8 = concatenate([up8, conv2])\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up8)\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    " \n",
    "up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "up9 = concatenate([up9, conv1], axis=3)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up9)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    " \n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    " \n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs = Input((height_shape, width_shape, 3))\n",
    "\n",
    "#contracting path\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
    "conv1 = Dropout(0.1)(conv1)\n",
    "conv1 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv1)\n",
    "maxp1 = MaxPooling2D((2, 2))(conv1)\n",
    "\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp1)\n",
    "conv2 = Dropout(0.1)(conv2)\n",
    "conv2 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv2)\n",
    "maxp2 = MaxPooling2D((2, 2))(conv2)\n",
    " \n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp2)\n",
    "conv3 = Dropout(0.2)(conv3)\n",
    "conv3 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv3)\n",
    "maxp3 = MaxPooling2D((2, 2))(conv3)\n",
    " \n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp3)\n",
    "conv4 = Dropout(0.2)(conv4)\n",
    "conv4 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv4)\n",
    "maxp4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    " \n",
    "conv5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(maxp4)\n",
    "conv5 = Dropout(0.3)(conv5)\n",
    "conv5 = Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv5)\n",
    "\n",
    "#expansive path\n",
    "up6 = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(conv5)\n",
    "up6 = concatenate([up6, conv4])\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up6)\n",
    "conv6 = Dropout(0.2)(conv6)\n",
    "conv6 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv6)\n",
    " \n",
    "up7 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv6)\n",
    "up7 = concatenate([up7, conv3])\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up7)\n",
    "conv7 = Dropout(0.2)(conv7)\n",
    "conv7 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv7)\n",
    " \n",
    "up8 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv7)\n",
    "up8 = concatenate([up8, conv2])\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up8)\n",
    "conv8 = Dropout(0.1)(conv8)\n",
    "conv8 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv8)\n",
    " \n",
    "up9 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv8)\n",
    "up9 = concatenate([up9, conv1], axis=3)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(up9)\n",
    "conv9 = Dropout(0.1)(conv9)\n",
    "conv9 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(conv9)\n",
    " \n",
    "outputs = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    " \n",
    "model = Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "%load_ext tensorboard\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit(X_train, Y_train, validation_split=0.1, batch_size=batch_size, epochs=epochs, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs --host localhost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test, verbose=2)\n",
    "plt.imshow(np.squeeze(preds[13]))\n",
    "plt.show()\n",
    "plt.imshow(X_test[13])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Classimg",
   "language": "python",
   "name": "classimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
